# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nOnagikNecYyyqEOygBrJMR0yuDq6Qk2
"""

!pip install scikit-learn spacy
!python -m spacy download en_core_web_sm

import spacy
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Sample dataset of grammatically correct and incorrect sentences
# For real implementation, you would want a much larger dataset
data = [
    ("This is a grammatically correct sentence.", 1),
    ("She are going to the store.", 0),
    ("He loves programming.", 1),
    ("I is going to the park.", 0),
    ("The weather is nice today.", 1),
    ("I don't know where she gone.", 0)
]

# Split the dataset into texts and labels
texts, labels = zip(*data)

# Preprocess text using spaCy (tokenization and lemmatization)
def preprocess_text(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop])

processed_texts = [preprocess_text(text) for text in texts]

# Convert the text data into feature vectors
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(processed_texts)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.3, random_state=42)

# Train a Logistic Regression classifier
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
print("Classification Report:\n", classification_report(y_test, y_pred))

# Function to classify new sentences
def classify_text(text):
    processed = preprocess_text(text)
    vectorized = vectorizer.transform([processed])
    prediction = model.predict(vectorized)
    return "Correct" if prediction == 1 else "Incorrect"

# Test with new sentences
test_sentence = "He is reading a book"
print(f"Sentence: '{test_sentence}' is {classify_text(test_sentence)}")

test_sentence = "She going to the shop"
print(f"Sentence: '{test_sentence}' is {classify_text(test_sentence)}")

import joblib

# After training the model
joblib.dump(model, 'grammar_classifier_model.pkl')  # Save the model
joblib.dump(vectorizer, 'vectorizer.pkl')  # Save the vectorizer

print("Model and vectorizer saved successfully.")

!pip install firebase-admin

import firebase_admin
from firebase_admin import credentials, firestore

# Check if the Firebase app is already initialized
if not firebase_admin._apps:
    # Initialize Firebase Admin SDK with the service account key if not initialized already
    cred = credentials.Certificate("/content/project1-se-firebase-adminsdk-fbsvc-662649a1fd.json")  # Replace with your .json path
    firebase_admin.initialize_app(cred)

# Initialize Firestore client
db = firestore.client()

# Sample test sentences and labels
test_data = [
    {"sentence": "This is a grammatically correct sentence.", "label": 1},
    {"sentence": "She are going to the store.", "label": 0},
    {"sentence": "He loves programming.", "label": 1},
    {"sentence": "I is going to the park.", "label": 0},
    {"sentence": "The weather is nice today.", "label": 1},
    {"sentence": "I don't know where she gone.", "label": 0}
]

# Upload the test data to Firestore
for index, item in enumerate(test_data):
    # Creating a new document in the "grammar_test_data" collection
    doc_ref = db.collection('grammar_test_data').document(f"sentence_{index+1}")
    doc_ref.set(item)

print("Test sentences uploaded successfully.")